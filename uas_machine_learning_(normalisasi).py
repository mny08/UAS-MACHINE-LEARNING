# -*- coding: utf-8 -*-
"""UAS MACHINE LEARNING (Normalisasi)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RF9Wt5HW5_WxDJ4jmE4314HHRf58LLF_

IMPORT LIBRARY YANG DIBUTUHKAN
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import scipy
import numpy
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
!pip install impyute
import sys
from impyute.imputation.cs import fast_knn
from impyute.imputation.cs import mice
import seaborn as sns
!pip install matplotlib
sns.set(style="white", color_codes=True)
from matplotlib import pyplot
from sklearn.preprocessing import Normalizer
import seaborn as sns
# %matplotlib inline

sns.set_style("whitegrid")

"""LOAD DATA"""

from sklearn import preprocessing
df = pd.read_csv('DATA PANEN d.csv', delimiter=";", names = [  'Lunas Panaen (2020)', 'Luas Panen(2019)', 'Lunas Panen (2018)', 'Produksi 2020', 'Produksi 2019', 'Produksi 2018', 'Produksi ton 2020', 'Produksi ton 2019', 'Produksi ton 2018', 'PROVINSI'])

x = df.iloc[:, [0,1,2,3,4,5,6,7,8]].values

df.head()

"""DESKRIPSI DATA"""

names

X = df[names]
y = df.PROVINSI
x

df.max()

df.min()

"""PRAPROSES DATA

NORMALISASI
"""

from sklearn import preprocessing
x = df.values #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df = pd.DataFrame(x_scaled)

"""CLEANING DATA SET"""

df.isnull().sum()

sns.heatmap(df.isnull(),cbar=False)
plt.title('data COVID19 Value')
plt.show()

"""EXPLORE DATA"""

df.info()

df.describe

df.count

df.max()

df.mean()

df.min()

"""VISUALISASI DATA"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

df.plot()
pyplot.xlabel('jumlah')
pyplot.ylabel('variabel')
pyplot.show()

df.hist()
plt.show()

"""MENENTUKAN JUMLAH CLUSTER DENGAN  METODE ELBOW"""

Error =[]
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i).fit(x)
    kmeans.fit(x)
    Error.append(kmeans.inertia_)
import matplotlib.pyplot as plt
plt.plot(range(1, 11), Error)
plt.title('Elbow method')
plt.xlabel('No of clusters')
plt.ylabel('Error')
plt.show()

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=4)

kmeans.fit(df.drop(9,axis=1))

kmeans.cluster_centers_

kmeans.labels_

plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1])

import numpy as np

unique, counts = np.unique(kmeans.labels_, return_counts=True)

dict_data = dict(zip(unique, counts))
dict_data

import seaborn as sns
df["cluster"] = kmeans.labels_

df

df.cluster

df.plot()
pyplot.xlabel('jumlah')
pyplot.ylabel('variabel')
pyplot.show()

df.hist()
plt.show()

df.plot(kind='density',subplots=True,sharex=False)
plt.show()

"""MENGHITUNG NILAI AKURASI DENGAN CONFUSION MATRIX"""

#Create confusion matrix and classification report, comparing the new columns to the KMeans Labels (predicted Private/Public)
from sklearn.metrics import confusion_matrix,classification_report

print(confusion_matrix(df['cluster'],kmeans.labels_))
print(classification_report(df['cluster'],kmeans.labels_))